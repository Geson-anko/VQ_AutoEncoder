{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to VQ AutoEncoder clutstering tutorial!\n",
    "ここでは、VQ (Vector Quantized) AutoEncoderによるでは、教師なしクラスタリング手法を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意事項\n",
    "このチュートリアルは演算負荷が高いためGPU環境が必要です。  \n",
    "Google Colab で実行している方は、ページ上部から**ランタイム** &rarr; **ランタイムのタイプを変更** をクリックし **ハードウェアアクセラレータ** を *None* から *GPU* に変更してください。  \n",
    "GPUが使用可能かどうかは次のコードブロックを実行することで分かります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"GPU:\",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインストールとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning \n",
    "!pip install torchsummaryX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import pytorch_lightning as pl\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision.utils import make_grid\n",
    "from typing import *\n",
    "from datetime import datetime\n",
    "from torchsummaryX import summary\n",
    "from torch.utils import data as dutil\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムの説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantizing(nn.Module):\n",
    "\n",
    "    __initialized:bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self, num_quantizing:int, quantizing_dim:int, _weight:torch.Tensor = None,\n",
    "        initialize_by_dataset:bool = True, mean:float = 0.0, std:float = 1.0,\n",
    "        dtype:torch.dtype = None, device:torch.device = None\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert num_quantizing > 0\n",
    "        assert quantizing_dim > 0\n",
    "        self.num_quantizing = num_quantizing\n",
    "        self.quantizing_dim = quantizing_dim\n",
    "        self.initialize_by_dataset = initialize_by_dataset\n",
    "        self.mean,self.std = mean,std\n",
    "\n",
    "        if _weight is None:\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.empty(num_quantizing, quantizing_dim ,dtype=dtype,device=device)\n",
    "            )\n",
    "            nn.init.normal_(self.weight, mean=mean, std=std)\n",
    "\n",
    "            if initialize_by_dataset:\n",
    "                self.__initialized = False\n",
    "                self.__initialized_length= 0\n",
    "\n",
    "        elif type(_weight) is torch.Tensor:\n",
    "            assert _weight.dim() == 2\n",
    "            assert _weight.size(0) == num_quantizing\n",
    "            assert _weight.size(1) == quantizing_dim\n",
    "            self.weight = nn.Parameter(_weight.to(device).to(dtype))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Weight type is unknown type! {}\".format(type(_weight)))\n",
    "\n",
    "    def forward(self,x:torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        x   : shape is (*, E), and weight shape is (Q, E). \n",
    "        return -> ( quantized : shape is (*, E), quantized_idx : shape is (*,) )\n",
    "        \"\"\"\n",
    "        input_size = x.shape\n",
    "        h = x.view(-1,self.quantizing_dim) # shape is (B,E)\n",
    "\n",
    "        if not self.__initialized and self.initialize_by_dataset:\n",
    "            getting_len = self.num_quantizing - self.__initialized_length\n",
    "            init_weight = h[torch.randperm(len(h))[:getting_len]]\n",
    "            \n",
    "            _until = self.__initialized_length + init_weight.size(0)\n",
    "            self.weight.data[self.__initialized_length:_until] = init_weight\n",
    "            self.__initialized_length = _until\n",
    "            print('replaced weight')\n",
    "\n",
    "            if _until >= self.num_quantizing:\n",
    "                self.__initialized = True\n",
    "                print('initialized')\n",
    "        \n",
    "        delta = self.weight.unsqueeze(0) - h.unsqueeze(1) # shape is (B, Q, E)\n",
    "        dist =torch.sum(delta*delta, dim=-1) # shape is (B, Q)\n",
    "        q_idx = torch.argmin(dist,dim=-1) # shape is (B,)\n",
    "        q_data = self.weight[q_idx] # shape is (B, E)\n",
    "\n",
    "        return q_data.view(input_size), q_idx.view(input_size[:1])\n",
    "    \n",
    "    @property\n",
    "    def is_initialized(self):\n",
    "        return self.__initialized\n",
    "\n",
    "    @is_initialized.setter\n",
    "    def is_initialized(self, b:bool):\n",
    "        self.__initialized = b\n",
    "        if b:\n",
    "            self.__initialized_length= num_quantizings\n",
    "        else:\n",
    "            self.__initialized_length = 0\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,h):\n",
    "        super().__init__()\n",
    "        self.channels = h.channels\n",
    "        self.width = h.width\n",
    "        self.height = h.height\n",
    "        self.input_size = (1,h.channels,h.width,h.height)\n",
    "        self.output_size = (1,h.quantizing_dim)\n",
    "        self.h = h\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(784,256),nn.ReLU(),\n",
    "            nn.Linear(256,128),nn.ReLU(),\n",
    "            nn.Linear(128,h.quantizing_dim),nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        y = self.layers(x)\n",
    "        return y\n",
    "    \n",
    "    def summary(self):\n",
    "        dummy = torch.randn(self.input_size)\n",
    "        summary(self,dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,h):\n",
    "        super().__init__()\n",
    "        self.channels = h.channels\n",
    "        self.width = h.width\n",
    "        self.height = h.height\n",
    "        self.input_size = (1,h.quantizing_dim)\n",
    "        self.output_size = (1,h.channels,h.width,h.height)\n",
    "        self.h = h\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(h.quantizing_dim,128),nn.ReLU(),\n",
    "            nn.Linear(128,256),nn.ReLU(),\n",
    "            nn.Linear(256,784),nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x:torch.Tensor):\n",
    "        y = self.layers(x)\n",
    "        y = y.view(-1,self.channels,self.height,self.width)\n",
    "        return y\n",
    "\n",
    "    def summary(self):\n",
    "        dummy = torch.randn(self.input_size)\n",
    "        summary(self,dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQ AutoEncoder\n",
    "学習の処理を簡単に書くために、`pytorch-lightning`というライブラリを使用します。\n",
    "`pytorch-lightning`はPyTorchのラッパーです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VQ_AutoEncoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,h):\n",
    "        super().__init__()\n",
    "        self.model_name = h.model_name\n",
    "        self.h = h\n",
    "        self.num_quantizing = h.num_quantizing\n",
    "        self.quantizing_dim = h.quantizing_dim\n",
    "        self.lr = h.lr\n",
    "        self.my_hparams_dict = h.get()\n",
    "\n",
    "        # set criterion\n",
    "        self.reconstruction_loss = nn.MSELoss()\n",
    "        self.quantizing_loss = nn.MSELoss()\n",
    "        \n",
    "        # set histogram\n",
    "        self.q_hist = torch.zeros(self.num_quantizing,dtype=torch.int)\n",
    "        self.q_hist_idx = np.arange(self.num_quantizing)\n",
    "        # set layers\n",
    "        self.encoder = Encoder(h)\n",
    "        self.quantizer = Quantizing(h.num_quantizing,h.quantizing_dim)\n",
    "        self.decoder = Decoder(h)\n",
    "\n",
    "        self.input_size = self.encoder.input_size\n",
    "        self.output_size = self.input_size\n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        h = self.encoder(x)\n",
    "        Qout,Qidx = self.quantizer(h)\n",
    "        y = self.decoder(Qout)\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(),self.lr)\n",
    "        return optim\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def set_quantizing_weight(self,data_loader,device='cpu'):\n",
    "        self.quantizer.is_initialized = False\n",
    "        for batch in data_loader:\n",
    "            data,_ = batch\n",
    "            data = data.to(device)\n",
    "            Eout = self.encoder(data)\n",
    "            _ = self.quantizer(Eout)\n",
    "            if self.quantizer.is_initialized:\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def on_fit_start(self) -> None:\n",
    "        self.logger.log_hyperparams(self.my_hparams_dict)\n",
    "\n",
    "    def training_step(self,batch,idx):\n",
    "        data,_  = batch\n",
    "        self.view_data = data\n",
    "        Eout = self.encoder(data)\n",
    "        Qtgt = Eout.detach()\n",
    "        Qout,Qidx = self.quantizer(Qtgt)\n",
    "        out = self.decoder(Eout)\n",
    "\n",
    "        # loss\n",
    "        r_loss = self.reconstruction_loss(out,data)\n",
    "        q_loss = self.quantizing_loss(Qout,Qtgt)\n",
    "        loss = r_loss + q_loss\n",
    "\n",
    "        # log\n",
    "        rq_loss = self.reconstruction_loss(self.decoder(Qout),data)\n",
    "        self.log('loss',loss)\n",
    "        self.log('reconstruction_loss',r_loss)\n",
    "        self.log('quantizing_loss',q_loss)\n",
    "        self.log('reconstructed_quantizing_loss',rq_loss)\n",
    "\n",
    "        idx,count = torch.unique(Qidx,return_counts = True)\n",
    "        self.q_hist[idx.cpu()] += count.cpu()\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if (self.current_epoch+1) % self.h.view_interval ==0:\n",
    "            # image logging\n",
    "            data = self.view_data[:self.h.max_view_imgs].float()\n",
    "            data_len = len(data)\n",
    "            Eout = self.encoder(data)\n",
    "            Qout,Qidx = self.quantizer(Eout)\n",
    "            out = self.decoder(Eout)\n",
    "            Qdecoded = self.decoder(Qout)\n",
    "\n",
    "            grid_img = make_grid(torch.cat([data,out,Qdecoded],dim=0),nrow=data_len)\n",
    "            self.logger.experiment.add_image(\"MNIST Quantizings\",grid_img,self.current_epoch)\n",
    "\n",
    "            # histogram logging\n",
    "            fig = plt.figure(figsize=(6.4,4.8))\n",
    "            ax = fig.subplots()\n",
    "            ax.bar(self.q_hist_idx,self.q_hist)\n",
    "            \n",
    "            quantized_num = len(self.q_hist[self.q_hist!=0])\n",
    "            q_text = f'{quantized_num}/{self.num_quantizing}'\n",
    "            ax.text(0.9,1.05,q_text,ha='center',va='center',transform=ax.transAxes,fontsize=12)\n",
    "            ax.set_xlabel('weight index')\n",
    "            ax.set_ylabel('num')\n",
    "            self.logger.experiment.add_figure('Quantizing Histogram',fig,self.current_epoch)\n",
    "            \n",
    "        self.q_hist.zero_()\n",
    "\n",
    "    def summary(self,tensorboard=False):\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        dummy = torch.randn(self.input_size)\n",
    "        summary(self,dummy)\n",
    "\n",
    "        if tensorboard:\n",
    "            writer = SummaryWriter(comment=self.model_name,log_dir=\"VQAE_log\")\n",
    "            writer.add_graph(self,dummy)\n",
    "            writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch-lightning`では下のような形でモデルを定義することができます。  \n",
    "```python\n",
    "class ModelName(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, arguments): # required\n",
    "        super().__init__()\n",
    "        ################################################\n",
    "        # この中でレイヤーや、criterion(Loss関数)を定義します。\n",
    "        self.criterion = SomeLossFunc()\n",
    "        self.layer = SomeLayers()\n",
    "        ################################################\n",
    "\n",
    "    def forward(self, input): # not required (when training)\n",
    "        ################################################\n",
    "        # この中にデータの流れを書きますが、学習する際にこの\n",
    "        # forward methodは使われません。\n",
    "        output = self.layer(input)\n",
    "        ################################################\n",
    "        return output\n",
    "\n",
    "    def configure_optimizers(self): # required\n",
    "        ################################################\n",
    "        # この中でoptimizerを定義して、returnで返します。\n",
    "        optim = torch.optim.SomeOptimizer(self.parameters(), lr=lr)\n",
    "        ################################################\n",
    "        return optim\n",
    "    \n",
    "    def training_step(self, batch, idx): # required\n",
    "        ################################################\n",
    "        # この中で学習する時のデータの流れを書きます。学習するとき\n",
    "        # は\"損失\"まで計算し、それを return で返します。学習時に\n",
    "        # 記録したい値は self.log(\"name\", value) で記録するこ\n",
    "        # とができます。\n",
    "        input, answer = batch # extracting\n",
    "        output = self.layer(input) # flow\n",
    "        loss = self.criterion(output, answer) # calculate loss\n",
    "        self.log(\"loss\",loss) # log\n",
    "        return loss # return (required)\n",
    "        ################################################\n",
    "\n",
    "    def validation_step(self, batch, idx): # not required when you don't need the validation.\n",
    "        ################################################\n",
    "        # この中に検証用データセットでの処理を書きます。この関数で\n",
    "        # は値をreturnしなくて良いです。self.log(\"name\", value)\n",
    "        # で値を記録してください。\n",
    "        # Trainerにvalidation用のDataLoaderを与えなかった場合、\n",
    "        # この関数はつかわれません。　\n",
    "        ################################################\n",
    "```\n",
    "\n",
    "Event drivenなので、他にも様々な関数が用意されています。pytorch_lightningの`Trainer`が自動的にそのタイミングでオーバーライドされた関数を呼び出します。\n",
    "```python\n",
    "model = ModelName(arguments)\n",
    "trainer = pl.Trainer(gpus=1,precsion=16, max_epochs=10,...)\n",
    "trainer.fit(model,train_loader, validation_loader)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class hparam:\n",
    "    model_name:str = \"VQ_AutoEncoder\"\n",
    "    max_view_imgs = 16\n",
    "    view_interval = 10\n",
    "\n",
    "    lr:float = 0.001\n",
    "\n",
    "    num_quantizing:int = 32\n",
    "    quantizing_dim:int = 32\n",
    "\n",
    "    channels:int = 1\n",
    "    width:int = 28\n",
    "    height:int = 28\n",
    "\n",
    "    def get(self):\n",
    "        return self.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Tensor Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"VQAE_log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットのロード(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "dataset = MNIST(\n",
    "    \"data\",train=False,download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 時刻を取得する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now(strf:str = '%Y-%m-%d_%H-%M-%S'):\n",
    "    now = datetime.now().strftime(strf)\n",
    "    return now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの保存について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_dir():\n",
    "    if not os.path.exists(\"params\"):\n",
    "        os.makedirs(\"params\")\n",
    "        \n",
    "def save_params(model:VQ_AutoEncoder, now):\n",
    "    param_dir()\n",
    "    torch.save(model.encoder.state_dict(),f\"params/{model.model_name}_{now}.encoder.pth\")\n",
    "    torch.save(model.decoder.state_dict(),f\"params/{model.model_name}_{now}.decoder.pth\")\n",
    "    torch.save(model.quantizer.state_dict(),f\"params/{model.model_name}_{now}.quantizing.pth\")\n",
    "    torch.save(model.state_dict(),f\"params/{model.model_name}_{now}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データローダーの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "dataloader = dutil.DataLoader(\n",
    "    dataset, BATCH_SIZE,shuffle=True, num_workers=0, pin_memory=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch lightning の key words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_kwds = {\n",
    "    \"gpus\": 1 if torch.cuda.is_available() else 0,\n",
    "    \"precision\": 16,\n",
    "    \"max_epochs\": 500,\n",
    "    \"log_every_n_steps\":5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習（1回目）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### インスタンス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hparam(model_name=\"VQAE_pure\")\n",
    "model = VQ_AutoEncoder(h)\n",
    "model.summary(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quantinzing Weight をセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_quantizing_weight(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl_loggers.TensorBoardLogger(\"VQAE_log/pure\")\n",
    "trainer = pl.Trainer(logger=logger, **pl_kwds)\n",
    "trainer.fit(model, dataloader)\n",
    "logger.close()\n",
    "now = get_now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### パラメータ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params(model,now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### なぜうまくいかないのか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習（通常）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### パラメータのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_param(model:VQ_AutoEncoder):\n",
    "    model.encoder.load_state_dict(torch.load(\"params/~.encoder.pth\"))    \n",
    "    model.decoder.load_state_dict(torch.load(\"params/~.decoder.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### インスタンスと実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(settings:Dict[str,Any], pl_kwds:Dict[str, Any]):\n",
    "    h = hparam(**settings)\n",
    "    model = VQ_AutoEncoder(h)\n",
    "    load_trained_param(model)\n",
    "    model.set_quantizing_weight(dataloader)\n",
    "    logger = pl_loggers.TensorBoardLogger(\"VQAE_log/fromTraining\")\n",
    "    trainer = pl.Trainer(logger=logger, **pl_kwds)\n",
    "    trainer.fit(model, dataloader)\n",
    "    now = get_now()\n",
    "    logger.close()\n",
    "    save_params(model, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex) changing `num_quantizing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_kwds = {\n",
    "    \"gpus\": 1 if torch.cuda.is_available() else 0,\n",
    "    \"precision\": 16,\n",
    "    \"max_epochs\": 100,\n",
    "    \"log_every_n_steps\":5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_quantizings = [8,32,128]\n",
    "for nq in num_quantizings:\n",
    "    setting = {\n",
    "        \"model_name\":\"vqae_changing_num_quantizing_{}\".format(nq),\n",
    "        \"num_quantizing\":nq,\n",
    "    }\n",
    "    train(setting, pl_kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果を解析する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 考えること"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4467f1926f03d6fcd44316305074fb8c0b3cdc10977f45ea461091401ebc85a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('JARVIS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

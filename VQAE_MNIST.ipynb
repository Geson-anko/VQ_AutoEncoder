{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to VQ AutoEncoder clutstering tutorial!\n",
    "ここでは、VQ (Vector Quantized) AutoEncoderによるでは、教師なしクラスタリング手法を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインストールとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning \n",
    "!pip install torchsummaryX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import pytorch_lightning as pl\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision.utils import make_grid\n",
    "from typing import *\n",
    "from datetime import datetime\n",
    "from torchsummaryX import summary\n",
    "from torch.utils import data as dutil\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning import loggers as pl_loggers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムの説明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantizing(nn.Module):\n",
    "\n",
    "    __initialized:bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self, num_quantizing:int, quantizing_dim:int, _weight:torch.Tensor = None,\n",
    "        initialize_by_dataset:bool = True, mean:float = 0.0, std:float = 1.0,\n",
    "        dtype:torch.dtype = None, device:torch.device = None\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert num_quantizing > 0\n",
    "        assert quantizing_dim > 0\n",
    "        self.num_quantizing = num_quantizing\n",
    "        self.quantizing_dim = quantizing_dim\n",
    "        self.initialize_by_dataset = initialize_by_dataset\n",
    "        self.mean,self.std = mean,std\n",
    "\n",
    "        if _weight is None:\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.empty(num_quantizing, quantizing_dim ,dtype=dtype,device=device)\n",
    "            )\n",
    "            nn.init.normal_(self.weight, mean=mean, std=std)\n",
    "\n",
    "            if initialize_by_dataset:\n",
    "                self.__initialized = False\n",
    "                self.__initialized_length= 0\n",
    "\n",
    "        elif type(_weight) is torch.Tensor:\n",
    "            assert _weight.dim() == 2\n",
    "            assert _weight.size(0) == num_quantizing\n",
    "            assert _weight.size(1) == quantizing_dim\n",
    "            self.weight = nn.Parameter(_weight.to(device).to(dtype))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Weight type is unknown type! {}\".format(type(_weight)))\n",
    "\n",
    "    def forward(self,x:torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        x   : shape is (*, E), and weight shape is (Q, E). \n",
    "        return -> ( quantized : shape is (*, E), quantized_idx : shape is (*,) )\n",
    "        \"\"\"\n",
    "        input_size = x.shape\n",
    "        h = x.view(-1,self.quantizing_dim) # shape is (B,E)\n",
    "\n",
    "        if not self.__initialized and self.initialize_by_dataset:\n",
    "            getting_len = self.num_quantizing - self.__initialized_length\n",
    "            init_weight = h[torch.randperm(len(h))[:getting_len]]\n",
    "            \n",
    "            _until = self.__initialized_length + init_weight.size(0)\n",
    "            self.weight.data[self.__initialized_length:_until] = init_weight\n",
    "            self.__initialized_length = _until\n",
    "            print('replaced weight')\n",
    "\n",
    "            if _until >= self.num_quantizing:\n",
    "                self.__initialized = True\n",
    "                print('initialized')\n",
    "        \n",
    "        delta = self.weight.unsqueeze(0) - h.unsqueeze(1) # shape is (B, Q, E)\n",
    "        dist =torch.sum(delta*delta, dim=-1) # shape is (B, Q)\n",
    "        q_idx = torch.argmin(dist,dim=-1) # shape is (B,)\n",
    "        q_data = self.weight[q_idx] # shape is (B, E)\n",
    "\n",
    "        return q_data.view(input_size), q_idx.view(input_size[:1])\n",
    "    \n",
    "    @property\n",
    "    def is_initialized(self):\n",
    "        return self.__initialized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,h):\n",
    "        super().__init__()\n",
    "        self.input_size = (1,h.channels,h.width,h.height)\n",
    "        self.output_size = (1,h.quantizing_dim)\n",
    "        self.h = h\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(784,256),nn.ReLU(),\n",
    "            nn.Linear(256,128),nn.ReLU(),\n",
    "            nn.Linear(128,h.quantizing_dim),nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        y = self.layers(x)\n",
    "        return y\n",
    "    \n",
    "    def summary(self):\n",
    "        dummy = torch.randn(self.input_size)\n",
    "        summary(self,dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,h):\n",
    "        super().__init__()\n",
    "        self.input_size = (1,h.quantizing_dim)\n",
    "        self.output_size = (1,h.channels,h.width,h.height)\n",
    "        self.h = h\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(h.quantizing_dim,128),nn.ReLU(),\n",
    "            nn.Linear(128,256),nn.ReLU(),\n",
    "            nn.Linear(256,784),nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x:torch.Tensor):\n",
    "        y = self.layers(x)\n",
    "        y = y.view(-1,self.channels,self.height,self.width)\n",
    "        return y\n",
    "\n",
    "    def summary(self):\n",
    "        dummy = torch.randn(self.input_size)\n",
    "        summary(self,dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQ AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VQ_AutoEncoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,h):\n",
    "        super().__init__()\n",
    "        self.model_name = h.model_name\n",
    "        self.h = h\n",
    "        self.num_quantizing = h.num_quantizing\n",
    "        self.quantizing_dim = h.quantizing_dim\n",
    "        self.lr = h.lr\n",
    "        self.my_hparams_dict = h.get()\n",
    "\n",
    "        # set criterion\n",
    "        self.reconstruction_loss = nn.MSELoss()\n",
    "        self.quantizing_loss = nn.MSELoss()\n",
    "        \n",
    "        # set histogram\n",
    "        self.q_hist = torch.zeros(self.num_quantizing,dtype=torch.int)\n",
    "        self.q_hist_idx = np.arange(self.num_quantizing)\n",
    "        # set layers\n",
    "        self.encoder = Encoder(h)\n",
    "        self.quantizer = Quantizing(h.num_quantizing,h.quantizing_dim)\n",
    "        self.decoder = Decoder(h)\n",
    "\n",
    "        self.input_size = self.encoder.input_size\n",
    "        self.output_size = self.input_size\n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        h = self.encoder(x)\n",
    "        Qout,Qidx = self.quantizer(h)\n",
    "        y = self.decoder(Qout)\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(self.parameters(),self.lr)\n",
    "        return optim\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def set_quantizing_weight(self,data_loader,device='cpu'):\n",
    "        for batch in data_loader:\n",
    "            data,_ = batch\n",
    "            data = data.to(device)\n",
    "            Eout = self.encoder(data)\n",
    "            _ = self.quantizer(Eout)\n",
    "            if self.quantizer.is_initialized:\n",
    "                break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def on_fit_start(self) -> None:\n",
    "        self.logger.log_hyperparams(self.my_hparams_dict)\n",
    "\n",
    "    def training_step(self,batch,idx):\n",
    "        data,_  = batch\n",
    "        self.view_data = data\n",
    "        Eout = self.encoder(data)\n",
    "        Qtgt = Eout.detach()\n",
    "        Qout,Qidx = self.quantizer(Qtgt)\n",
    "        out = self.decoder(Eout)\n",
    "\n",
    "        # loss\n",
    "        r_loss = self.reconstruction_loss(out,data)\n",
    "        q_loss = self.quantizing_loss(Qout,Qtgt)\n",
    "        loss = r_loss + q_loss\n",
    "\n",
    "        # log\n",
    "        rq_loss = self.reconstruction_loss(self.decoder(Qout),data)\n",
    "        self.log('loss',loss)\n",
    "        self.log('reconstruction_loss',r_loss)\n",
    "        self.log('quantizing_loss',q_loss)\n",
    "        self.log('reconstructed_quantizing_loss',rq_loss)\n",
    "\n",
    "        idx,count = torch.unique(Qidx,return_counts = True)\n",
    "        self.q_hist[idx.cpu()] += count.cpu()\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def on_epoch_end(self) -> None:\n",
    "        if (self.current_epoch+1) % self.h.view_interval ==0:\n",
    "            # image logging\n",
    "            data = self.view_data[:self.h.max_view_imgs].float()\n",
    "            data_len = len(data)\n",
    "            Eout = self.encoder(data)\n",
    "            Qout,Qidx = self.quantizer(Eout)\n",
    "            out = self.decoder(Eout)\n",
    "            Qdecoded = self.decoder(Qout)\n",
    "\n",
    "            grid_img = make_grid(torch.cat([data,out,Qdecoded],dim=0),nrow=data_len)\n",
    "            self.logger.experiment.add_image(\"MNIST Quantizings\",grid_img,self.current_epoch)\n",
    "\n",
    "            # histogram logging\n",
    "            fig = plt.figure(figsize=(6.4,4.8))\n",
    "            ax = fig.subplots()\n",
    "            ax.bar(self.q_hist_idx,self.q_hist)\n",
    "            \n",
    "            quantized_num = len(self.q_hist[self.q_hist!=0])\n",
    "            q_text = f'{quantized_num}/{self.num_quantizing}'\n",
    "            ax.text(0.9,1.05,q_text,ha='center',va='center',transform=ax.transAxes,fontsize=12)\n",
    "            ax.set_xlabel('weight index')\n",
    "            ax.set_ylabel('num')\n",
    "            self.logger.experiment.add_figure('Quantizing Histogram',fig,self.current_epoch)\n",
    "            \n",
    "        self.q_hist.zero_()\n",
    "\n",
    "    def summary(self,tensorboard=False):\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        dummy = torch.randn(self.input_size)\n",
    "        summary(self,dummy)\n",
    "\n",
    "        if tensorboard:\n",
    "            writer = SummaryWriter(comment=self.model_name)\n",
    "            writer.add_graph(self,dummy)\n",
    "            writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class hparam:\n",
    "    model_name:str = \"VQ_AutoEncoder\"\n",
    "    max_view_imgs = 16\n",
    "    view_interval = 10\n",
    "\n",
    "    lr:float = 0.001\n",
    "\n",
    "    num_quantizing:int = 32\n",
    "    quantizing_dim:int = 32\n",
    "\n",
    "    def get(self):\n",
    "        return self.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットのロード(MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果を見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 考えること"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4467f1926f03d6fcd44316305074fb8c0b3cdc10977f45ea461091401ebc85a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('JARVIS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
